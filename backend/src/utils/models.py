"""
Data models for the embedding pipeline.

This module contains Pydantic models for the key entities in the system,
based on the data-model.md specification.
"""
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime
from enum import Enum


class Document(BaseModel):
    """
    Represents a unit of content extracted from the website (e.g., a page, section, or chapter)
    with its text content, metadata, and URL
    """
    id: Optional[str] = None
    url: str
    title: str
    content: str
    section: Optional[str] = None
    created_date: Optional[datetime] = None
    updated_date: Optional[datetime] = None
    checksum: Optional[str] = None
    description: Optional[str] = ""


class PipelineJobStatus(str, Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"


class PipelineJob(BaseModel):
    """
    A unit of work representing the processing of a website URL through the entire pipeline
    from ingestion to storage
    """
    id: Optional[str] = None
    url: str
    status: PipelineJobStatus = PipelineJobStatus.PENDING
    created_date: Optional[datetime] = None
    started_date: Optional[datetime] = None
    completed_date: Optional[datetime] = None
    error_message: Optional[str] = None
    processed_documents_count: int = 0
    total_documents_count: int = 0
    collection_name: Optional[str] = "rag_embeddings"


class Embedding(BaseModel):
    """
    A vector representation of document content generated by the Cohere model,
    associated with its source document
    """
    id: Optional[str] = None
    document_id: str
    vector: List[float]
    created_date: Optional[datetime] = None


class Metadata(BaseModel):
    """
    Information about the source document including URL, title, section, creation date,
    and any other relevant indexing information
    """
    document_id: str
    url: str
    title: str
    section: Optional[str] = None
    source_type: str = "docusaurus"
    additional_metadata: Optional[Dict[str, Any]] = {}


class Chunk(BaseModel):
    """
    A portion of a document that fits within the token limits of the embedding model
    """
    id: Optional[str] = None
    document_id: str
    content: str
    chunk_index: int = 0
    token_count: Optional[int] = None
    checksum: Optional[str] = None


# Response models for API endpoints
class ProcessUrlResponse(BaseModel):
    job_id: str
    status: str
    url: str
    estimated_completion: Optional[datetime] = None
    message: str


class JobStatusResponse(BaseModel):
    job_id: str
    status: str
    url: str
    documents_processed: int
    documents_failed: int
    embeddings_generated: int
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    message: str


class QueryResponse(BaseModel):
    query: str
    results: List[Dict[str, Any]]  # Contains document_id, url, title, content_snippet, similarity_score


class CollectionInfo(BaseModel):
    name: str
    document_count: int
    created_at: datetime


class CollectionsListResponse(BaseModel):
    collections: List[CollectionInfo]


# API Request models based on contracts/api-contract.md
class ProcessUrlRequest(BaseModel):
    url: str
    collection_name: str = "rag_embeddings"
    chunk_size: int = 1000
    batch_size: int = 10


class QueryRequest(BaseModel):
    query_text: str
    collection_name: str = "rag_embeddings"
    limit: int = 5


if __name__ == "__main__":
    # Example usage
    from uuid import uuid4
    
    # Create a sample document
    doc = Document(
        id=str(uuid4()),
        url="https://example.com/page",
        title="Sample Page",
        content="This is the content of the page",
        section="Introduction"
    )
    
    print(f"Document: {doc.title}")
    print(f"URL: {doc.url}")
    print(f"Content length: {len(doc.content)}")